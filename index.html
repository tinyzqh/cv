<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhiqiang He</title>

  <meta name="author" content="Zhiqiang He">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Zhiqiang He (何志强)
                  </p>

                  <p>
                    I have a master's degree from <a href="https://english.neu.edu.cn/">Northeastern
                      University</a>, and my research direction is Reinforcement Learning. My academic research journey began in <a href="https://jxaco.ecjtu.edu.cn/">
                      Jiangxi Province Advanced Control and Key Optimization Laboratory</a>. July 2017 to June 2019, I worked under the
                    guidance of Professor <a href="https://yzw.tzc.edu.cn/info/1021/1084.htm">Pengzhan Chen</a>. Subsequently, from July 2019 to June 2022, I continued my research at the <a
                      href="http://www.ise.neu.edu.cn/2019/0516/c5332a125036/page.htm">
                      Deep Learning and Advanced Intelligent Decision-Making Research Institute</a> , mentored by
                    Professor <a href="http://faculty.neu.edu.cn/wangjiao/zh_CN/zhym/75393/list/index.htm">Jiao
                      Wang</a>.
                  </p>

                  <p>
                    In my professional capacity, I interned as a Research Engineer at Baidu in Beijing, from June to September 2021. Subsequently, I served as a Reinforcement Learning
                    Algorithms Engineer at <a href="https://www.inspirai.com/">InspirAI</a> from June 2022 to May 2023.

                  </p>

                  <p style="text-align:center">
                    <a href="mailto:tinyzqh@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=v6o0Dz8AAAAJ">Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://github.com/tinyzqh/">Github</a> &nbsp;/&nbsp;
                    <a href="https://www.zhihu.com/people/zhiqianghe">Zhihu</a> &nbsp;/&nbsp;

                    <!-- <a href="zhiqianghe.blog.csdn.net">CSDN</a> -->
                    <a href="https://space.bilibili.com/40663224?spm_id_from=333.1007.0.0">BiliBili</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/tinyzqh.png"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/tinyzqh.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Experience</h2>
                  <p>
                    Between June 2022 and May 2023, I served as a Reinforcement Learning Algorithms Engineer at
                    <a href="https://www.inspirai.com/">InspirAI</a>. I put forward and optimized a general artificial intelligence modeling paradigm suitable for card games,
                    which was successfully deployed in Hearthstone, Dou Dizhu (defeated professional players), and
                    Guan Dan. Notably, The Doudizhu AI has been launched on the <a
                      href="https://www.taptap.cn/moment/356764971171842277">Taptop platform</a>.
                  </p>

                  <p>
                    In the summer of 2021, I had the opportunity to intern as a Research Engineer at Baidu AI Cloud in
                    Beijing. I  developed an innovative
                    multi-agent cooperative adversarial algorithm, which we termed Expert Data-Assisted Multi-Agent
                    Proximal Policy Optimization (EDA-MAPPO). Our work finally released a video
                    showing the performance of our algorithm, which has been published in <a
                      href="https://www.bilibili.com/video/BV1LV411p7KD/?spm_id_from=333.999.0.0&vd_source=d8ab7686ea514acb6635faa5d2227d61">Bilibili</a>
                    and the accompanying <a href="https://github.com/tinyzqh/light_mappo">Source Code</a>. 
                    At the same time, we called "superfly" team completed a <a href="https://www.ecole.ai/2021/ml4co-competition/">machine learning for combinatorial optimization competition</a> (9/23).
                    
                  </p>

                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Publication / Preprint</h2>
                </td>

              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://www.mdpi.com/1999-4893/11/5/65">
                  <span class="papertitle">Control Strategy of Speed Servo Systems Based on Deep Reinforcement
                    Learning
                  </span>
                </a>
                
                <br>
                <a href="https://yzw.tzc.edu.cn/info/1021/1084.htm">Pengzhan Chen</a>,
                <strong>Zhiqiang He</strong>,
                <a>Chuanxi Chen</a>,
                <a>Jiahong Xu</a>,
                <br>
                <em>Algorithms 11, no. 5: 65.<em>, 2018, <a href="https://github.com/tinyzqh/control-of-jump-systems-based-on-reinforcement-learning">Source Code</a>,
                     (Cited 47 times)
                    <br>
              </td>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320322001492">
                  <span class="papertitle">Erlang planning network: An iterative model-based reinforcement learning with
                    multi-perspective
                  </span>
                </a>
                
                <br>
                <a href="http://faculty.neu.edu.cn/wangjiao/zh_CN/zhym/75393/list/index.htm">Jiao Wang</a>,
                <a>Lemin Zhang</a>,
                <strong>Zhiqiang He</strong>,
                <a>Can Zhu</a>,
                <a>Zihui Zhao</a>,
                <br>
                <em>Pattern Recognition, 128: 108668.<em>, 2022, <a href="https://github.com/tinyzqh/Erlang-planning-network">Source Code</a>, (IF=8.5)
                    <br>
              </td>
            </tbody>
          </table>





          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    <a href="https://github.com/jonbarron/jonbarron_website">Credits</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


        </td>
      </tr>
  </table>
</body>

</html>